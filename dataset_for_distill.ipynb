{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import thinkdsp as tp\n",
    "import numpy as np\n",
    "# import librosa\n",
    "# from librosa.display import specshow\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "import numpy as np\n",
    "\n",
    "# Took it from here: https://github.com/iver56/audiomentations#usage-example\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "    Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rename(path):\n",
    "    path = re.sub(r'train_audio', 'train_spec_other', path)\n",
    "    path = re.sub(r'wav$', 'png', path)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def wav_to_png(path):\n",
    "    wave_ = tp.read_wave(path)\n",
    "    display(wave_.make_audio())\n",
    "    for i in range(20):\n",
    "        wave = copy.deepcopy(wave_)\n",
    "        wave.ys = augment(wave.ys, sample_rate=wave.framerate)\n",
    "        spectrogram = wave.make_spectrogram(seg_length=1024)\n",
    "        spectrogram.plot(high=5000)\n",
    "        \n",
    "        # Save augmented audio\n",
    "        audio_path = path[:-4] + f'_{i}' + path[-4:]\n",
    "        audio_path = re.sub('train_audio', 'train_audio_augmented', audio_path)\n",
    "        os.makedirs(os.path.dirname(audio_path), exist_ok=True)\n",
    "        tp.WavFileWriter(filename=audio_path, framerate=wave.framerate).write(wave)\n",
    "        \n",
    "        # Save spectrogram\n",
    "        plt.axis('off')\n",
    "        png_path = rename(audio_path)\n",
    "        os.makedirs(os.path.dirname(png_path), exist_ok=True)\n",
    "        plt.savefig(png_path, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = list(map(str, Path('train_audio_augmented').rglob('*.wav')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c440bfdea08d4928abff4f46c05c8b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with mp.Pool() as pool:\n",
    "    pool.map(wav_to_png, tqdm(wavs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    pretrained_model = tf.keras.models.load_model('my_model', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = sorted(os.listdir('train_audio'))\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c219b5d401ec4a6b80dbbe6e1bc9ac9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = []\n",
    "real = []\n",
    "for path in tqdm(wavs):\n",
    "    spec = rename(path)\n",
    "    with Image.open(spec) as img:\n",
    "        img = np.asarray(img)[None, :, :, :3]\n",
    "\n",
    "    cls = pretrained_model(img).numpy().argmax()\n",
    "    cls_name = class_names[cls]\n",
    "    predicted.append(cls_name)\n",
    "    \n",
    "    real_cls = re.findall(r'/(\\w+)/', path)[0]\n",
    "    real.append(real_cls)\n",
    "    \n",
    "#     dst = os.path.join('train_audio_for_distill', \n",
    "#                        cls_name, os.path.basename(path)\n",
    "#                       )\n",
    "#     os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "#     shutil.copy(path, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained model's accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565997186620819"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(predicted) == np.array(real)) / len(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
